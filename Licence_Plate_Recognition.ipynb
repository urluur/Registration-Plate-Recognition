{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import get_labels, load_dataset, preprocess_data\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Input, AveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_cv.losses import IoULoss\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "xml_path = './archive/annotations/'\n",
    "img_path = './archive/images/'\n",
    "dataset = {}\n",
    "\n",
    "# Loop over all the xml files and get the data\n",
    "for xml_file in os.listdir(xml_path):\n",
    "    x = os.path.join(xml_path, xml_file)\n",
    "    extracted = get_labels(x)\n",
    "    filename = extracted['filename']\n",
    "    dataset[filename] = extracted\n",
    "\n",
    "# Get all the data from images and xml files\n",
    "images, boxes = load_dataset(img_path, xml_path)\n",
    "\n",
    "# Preprocess the images and boxes (resize images and adjust boxes with scale)\n",
    "imgs_preprocessed, boxes_preprocessed = preprocess_data(images, boxes)\n",
    "\n",
    "# Splitting the data to train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs_preprocessed, boxes_preprocessed, test_size=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "def build_custom_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(3,3),\n",
    "\n",
    "        Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        AveragePooling2D(16),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        #Dropout(0.5),\n",
    "        Dense(4, activation='sigmoid')\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.01)  # Adjusted learning rate\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    ##model.compile(optimizer=optimizer, loss=IoULoss(bounding_box_format='xyxy', mode='linear'))\n",
    "    return model\n",
    "\n",
    "model = build_custom_model(input_shape=(500,500,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1e-5),\n",
    "    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=4, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and predict\n",
    "def load_and_predict(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    og_image = image.copy()\n",
    "\n",
    "    image = cv2.resize(image, (500,500))\n",
    "    image = image / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    predicted = model.predict(image)[0]\n",
    "\n",
    "    original_h, original_w = og_image.shape[:2]\n",
    "\n",
    "    xmin, ymin, xmax, ymax = predicted\n",
    "    xmin, xmax = int(xmin * original_w), int(xmax * original_w)\n",
    "    ymin, ymax = int(ymin * original_h), int(ymax * original_h)\n",
    "\n",
    "    # Draws a rectangle over the detected registration plate\n",
    "    cv2.rectangle(og_image, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
    "\n",
    "    # Get some margin, transform it to gray and read the text\n",
    "    img2 = og_image[ymin-10:ymax+10, xmin-10:xmax+10]\n",
    "    grey_img = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    text = pytesseract.image_to_string(grey_img)\n",
    "    \n",
    "    print(f\"Plate detected: {text}\")\n",
    "    # Display the text top right of the rectangle\n",
    "    cv2.putText(og_image, text, (xmin-5, ymin-5), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "    # TODO: Cover null case\n",
    "    cv2.imshow(\"Detected plate \" + text, og_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a test image\n",
    "load_and_predict('./img/testImg2.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
