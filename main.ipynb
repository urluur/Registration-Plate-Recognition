{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import easyocr\n",
    "import xml.etree.ElementTree as ET\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import get_labels, load_dataset, preprocess_data\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model # type: ignore\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Input, AveragePooling2D # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "from keras_cv.losses import IoULoss # type: ignore\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "xml_path = './archive/annotations/'\n",
    "img_path = './archive/images/'\n",
    "dataset = {}\n",
    "history = None\n",
    "\n",
    "# Loop over all the xml files and get the data\n",
    "for xml_file in os.listdir(xml_path):\n",
    "    x = os.path.join(xml_path, xml_file)\n",
    "    extracted = get_labels(x)\n",
    "    filename = extracted['filename']\n",
    "    dataset[filename] = extracted\n",
    "\n",
    "# Get all the data from images and xml files\n",
    "images, boxes = load_dataset(img_path, xml_path)\n",
    "\n",
    "# Preprocess the images and boxes (resize images and adjust boxes with scale)\n",
    "imgs_preprocessed, boxes_preprocessed = preprocess_data(images, boxes)\n",
    "\n",
    "# Splitting the data to train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs_preprocessed, boxes_preprocessed, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model building, saving, and loading functions\n",
    "def build_custom_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(3,3),\n",
    "\n",
    "        Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        AveragePooling2D(16),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        # Dropout(0.5),\n",
    "        Dense(4, activation='sigmoid')\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.01)  # Adjusted learning rate\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    # model.compile(optimizer=optimizer, loss=IoULoss(bounding_box_format='xyxy', mode='linear'))\n",
    "    return model\n",
    "\n",
    "def save_model(model, path):\n",
    "    model.save(path)\n",
    "\n",
    "def load_custom_model(path):\n",
    "    return load_model(path)\n",
    "\n",
    "model_path = 'models/model.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Check if the model already exists\n",
    "if os.path.exists(model_path):\n",
    "    model = load_custom_model(model_path)\n",
    "else:\n",
    "    model = build_custom_model(input_shape=(500,500,3))\n",
    "\n",
    "    # Got idea for callbacks from chatgpt\n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1e-5),\n",
    "        EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=4, callbacks=callbacks)\n",
    "\n",
    "    # Save the model after training\n",
    "    save_model(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roc curve and AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred[:, 1], pos_label=3)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-recall curve\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_pred[:, 1], pos_label=3)\n",
    "average_precision = average_precision_score(y_true, y_pred[:, 1], pos_label=3)\n",
    "\n",
    "plt.figure()\n",
    "plt.step(recall, precision, where='post')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "def load_and_predict(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    og_image = image.copy()\n",
    "\n",
    "    image = cv2.resize(image, (500, 500))\n",
    "    image = image / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    predicted = model.predict(image)[0]\n",
    "\n",
    "    original_h, original_w = og_image.shape[:2]\n",
    "\n",
    "    xmin, ymin, xmax, ymax = predicted\n",
    "    xmin, xmax = int(xmin * original_w), int(xmax * original_w)\n",
    "    ymin, ymax = int(ymin * original_h), int(ymax * original_h)\n",
    "\n",
    "    # Draws a rectangle over the detected registration plate\n",
    "    cv2.rectangle(og_image, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
    "\n",
    "    # Get some margin, transform it to gray and read the text\n",
    "    img2 = og_image[ymin-10:ymax+10, xmin-10:xmax+10]\n",
    "    grey_img = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use EasyOCR to detect text\n",
    "    result = reader.readtext(grey_img)\n",
    "    text = ' '.join([res[1] for res in result])\n",
    "    print(f\"Plate detected: {text}\")\n",
    "\n",
    "    # Display the text top right of the rectangle\n",
    "    cv2.putText(og_image, text, (xmin-5, ymin-5), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Detected plate \" + text, og_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "load_and_predict('./img/testImg.jpg')\n",
    "load_and_predict('./img/testImg2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                 | Prediction 1 | Prediction 2 |\n",
    "|-----------------|--------------|--------------|\n",
    "| Correct value   | CCC444       | KY70 CWT     |\n",
    "| Predicted value | CCC444       | KY70 CHT     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Prediction](img/prediction.jpg)\n",
    "\n",
    "![Prediction 2](img/prediction2.jpg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
